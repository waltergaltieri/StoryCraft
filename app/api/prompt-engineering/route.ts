import { NextRequest, NextResponse } from 'next/server';
import { config } from '@/lib/config';
import { MASTER_PROMPT_ENGINEERING } from '@/lib/prompt-engineering';

// Request types
interface PromptEngineeringRequest {
  scene: string;
}

// Response types
interface PromptEngineeringResponse {
  optimizedPrompt: string;
  originalScene: string;
  processingTime: number;
}

interface ErrorResponse {
  error: string;
  message: string;
  code?: string;
}

// OpenAI API types
interface OpenAIMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface OpenAIRequest {
  model: string;
  messages: OpenAIMessage[];
  max_tokens: number;
  temperature: number;
}

interface OpenAIResponse {
  choices: {
    message: {
      content: string;
    };
  }[];
}

export async function POST(request: NextRequest): Promise<NextResponse> {
  const startTime = Date.now();
  
  try {
    // Validate request body
    const body: PromptEngineeringRequest = await request.json();
    
    if (!body.scene || typeof body.scene !== 'string' || body.scene.trim().length === 0) {
      return NextResponse.json(
        { 
          error: 'Validation Error',
          message: 'Scene description is required and must be a non-empty string'
        } as ErrorResponse,
        { status: 400 }
      );
    }

    // Validate scene length (reasonable limits)
    if (body.scene.length > 2000) {
      return NextResponse.json(
        { 
          error: 'Validation Error',
          message: 'Scene description is too long (max 2000 characters)'
        } as ErrorResponse,
        { status: 400 }
      );
    }

    // Replace the $escena variable in the master prompt
    const finalPrompt = MASTER_PROMPT_ENGINEERING.replace(/\$escena/g, body.scene.trim());

    // Prepare OpenAI request
    const openAIRequest: OpenAIRequest = {
      model: 'gpt-4',
      messages: [
        {
          role: 'system',
          content: 'You are an expert prompt engineer specializing in optimizing video generation prompts for Google Veo 3. Your task is to transform scene descriptions into detailed, precise prompts that will generate high-quality videos. Focus on visual details, camera movements, lighting, composition, and artistic style while maintaining the original creative intent.'
        },
        {
          role: 'user',
          content: finalPrompt
        }
      ],
      max_tokens: 1000,
      temperature: 0.3 // Lower temperature for more consistent, precise prompts
    };

    // Call OpenAI API
    const openAIResponse = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${config.openaiApiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(openAIRequest)
    });

    if (!openAIResponse.ok) {
      const errorData = await openAIResponse.text();
      console.error('OpenAI API Error:', errorData);
      
      return NextResponse.json(
        { 
          error: 'OpenAI API Error',
          message: `Failed to optimize prompt: ${openAIResponse.status} ${openAIResponse.statusText}`,
          code: 'OPENAI_API_FAILED'
        } as ErrorResponse,
        { status: 500 }
      );
    }

    const openAIData: OpenAIResponse = await openAIResponse.json();
    const optimizedPrompt = openAIData.choices[0]?.message?.content;

    if (!optimizedPrompt) {
      return NextResponse.json(
        { 
          error: 'Generation Error',
          message: 'No optimized prompt generated by AI'
        } as ErrorResponse,
        { status: 500 }
      );
    }

    // Clean up the optimized prompt
    const cleanedPrompt = optimizedPrompt
      .trim()
      .replace(/^["']|["']$/g, '') // Remove quotes at start/end
      .replace(/\n\s*\n/g, '\n') // Remove extra blank lines
      .replace(/\s+/g, ' '); // Normalize whitespace

    // Validate the optimized prompt length
    if (cleanedPrompt.length < 10) {
      return NextResponse.json(
        { 
          error: 'Generation Error',
          message: 'Generated prompt is too short to be useful'
        } as ErrorResponse,
        { status: 500 }
      );
    }

    const processingTime = Date.now() - startTime;

    const response: PromptEngineeringResponse = {
      optimizedPrompt: cleanedPrompt,
      originalScene: body.scene,
      processingTime
    };

    return NextResponse.json(response);

  } catch (error) {
    console.error('Prompt Engineering API Error:', error);
    
    const processingTime = Date.now() - startTime;
    
    return NextResponse.json(
      { 
        error: 'Internal Server Error',
        message: error instanceof Error ? error.message : 'An unexpected error occurred',
        processingTime
      } as ErrorResponse & { processingTime: number },
      { status: 500 }
    );
  }
}

export async function GET(): Promise<NextResponse> {
  return NextResponse.json(
    { 
      error: 'Method Not Allowed',
      message: 'This endpoint only accepts POST requests'
    } as ErrorResponse,
    { status: 405 }
  );
} 